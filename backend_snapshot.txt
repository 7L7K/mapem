

===== 📄 config.py =====
# config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    DB_NAME: str = "genealogy_db"
    DB_USER: str = "postgres"
    DB_PASSWORD: str = ""
    DB_HOST: str = "localhost"
    DB_PORT: int = 5432
    PORT: int = 5050
    DEBUG: bool = True
    GOOGLE_MAPS_API_KEY: str = "AIza..."

    @property
    def DATABASE_URI(self):
        return f"postgresql+psycopg://{self.DB_USER}:{self.DB_PASSWORD}@{self.DB_HOST}:{self.DB_PORT}/{self.DB_NAME}"

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


settings = Settings()


===== 📄 db.py =====
from app.db import get_engine
from sqlalchemy.orm import sessionmaker
from app.config import settings  # <-- make sure settings is instantiated in config.py

engine = get_engine(settings.DATABASE_URI)
SessionLocal = sessionmaker(bind=engine)

def get_db_connection():
    return SessionLocal()

def get_engine():
    return engine


===== 📄 main.py =====
from flask import Flask
from flask_cors import CORS
import logging

from app.routes import register_routes
from app.models import Base
from app.config import Settings
from app.db import get_engine
from sqlalchemy.orm import sessionmaker

# Load settings from .env
settings = Settings()

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("app")

def create_app():
    app = Flask(__name__)
    
    CORS(app, supports_credentials=True, origins=[
        "http://localhost:5173", "http://127.0.0.1:5173"
    ])
    
    app.config['PROPAGATE_EXCEPTIONS'] = True
    app.config['TRAP_HTTP_EXCEPTIONS'] = True
    app.config['DEBUG'] = settings.DEBUG
    app.config['PORT'] = settings.PORT

    engine = get_engine(settings.DATABASE_URI)
    Base.metadata.create_all(engine)
    app.session_maker = sessionmaker(bind=engine)

    register_routes(app)

    @app.before_request
    def log_request_info():
        from flask import request
        logger.debug(f"➡️ {request.method} {request.path}")
        logger.debug(f"🔍 Headers: {dict(request.headers)}")
        logger.debug(f"🧠 Body: {request.get_data()}")

    return app


===== 📄 helpers.py =====

# File: helpers.py
# Created: 2025-04-06 16:00:50
# Edited by: King
# Last Edited: 2025-04-06 16:00:50
# Description: Utility functions like name normalization, fuzzy matching, etc.

import re
from fuzzywuzzy import fuzz
from app.db import get_engine
from sqlalchemy.orm import sessionmaker
from backend import config


def normalize_name(name):
    """Lowercase and strip whitespace."""
    return name.strip().lower()

def calculate_name_similarity(name1, name2):
    """Calculate fuzzy matching score between two names."""
    name1_norm = normalize_name(name1)
    name2_norm = normalize_name(name2)
    return fuzz.ratio(name1.strip().lower(), name2.strip().lower())

def calculate_match_score(individual1, individual2):
    """
    Calculate a match score based on name similarity and other factors.
    For now, we use name similarity; later you can add birth date proximity, shared locations, etc.
    """
    score = 0
    if hasattr(individual1, 'name') and hasattr(individual2, 'name'):
        score += calculate_name_similarity(individual1.name, individual2.name)
    return score

# Additional utility functions (e.g., tag processing from tags.py, check_names.py, etc.) can be added here.

import psycopg2
from backend import config

def get_db_connection():
    db_uri = (
        f"postgresql+psycopg://{config.DB_USER}:{config.DB_PASSWORD or ''}"
        f"@{config.DB_HOST}:{config.DB_PORT}/{config.DB_NAME}"
    )
    engine = get_engine(db_uri)
    Session = sessionmaker(bind=engine)
    return Session()


def normalize_location_name(name):
    return re.sub(r'\W+', '_', name.strip().lower())


===== 📄 clear_db.py =====
# clear_db.py
from app.db import get_engine
from sqlalchemy.orm import sessionmaker
from backend import app.models


def clear_database():
    # Connect to the database
    engine = create_engine('genealogy_db')
    Session = sessionmaker(bind=engine)
    session = Session()

    # Truncate all tables and reset auto-incrementing IDs
    try:
        session.execute('TRUNCATE TABLE individuals, families, events, locations, residence_history, tree_versions, tree_people, tree_relationships RESTART IDENTITY CASCADE')
        session.commit()
        print("Database cleared successfully!")
    except Exception as e:
        print(f"Error clearing database: {e}")
        session.rollback()
    finally:
        session.close()

if __name__ == "__main__":
    clear_database()


===== 📄 scan_schema.py =====
from sqlalchemy import inspect
from backend.config import DATABASE_URI
from app.db import get_engine


engine = create_engine(DATABASE_URI)
inspector = inspect(engine)

print("🧠 Scanning your PostgreSQL DB...\n")

for table_name in inspector.get_table_names():
    print(f"📄 Table: {table_name}")
    for column in inspector.get_columns(table_name):
        name = column["name"]
        dtype = str(column["type"])
        nullable = column["nullable"]
        default = column["default"]
        print(f"   └─ {name} ({dtype}){' NULLABLE' if nullable else ''}{f' DEFAULT={default}' if default else ''}")
    print("")


===== 📄 alembic/env.py =====
from logging.config import fileConfig

from app.db import get_engine
from sqlalchemy import pool

from alembic import context
from backend.models import Base  # Adjust the import path based on your folder structure


# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = get_engine(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
